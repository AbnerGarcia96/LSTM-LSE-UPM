# Segmentación e Identificación de Gestos en Imágenes y Vídeos: Aplicación en la Traducción de la Lengua de Signos Española (LSE)

En este repositorio se encuentra el código propuesto para el Trabajo de Fin de Máster Universitario en Software y Sistemas de la Universidad Politécnica de Madrid.

El objetivo de este programa es el de implementar modelos holísticos y redes neuronales LSTM para la identificación de gestos en la lengua de signos española. 

La estructura de archivos y carpetas es la siguiente:

- README.md: archivo con la descripción del repositorio.
- data/: carpeta con los datos de entrenamiento (actualmente las palabras "Hola" y "Gracias").
- predictor_LSE.m5: archivo con los pesos de la red neuronal previamente entrenada.
- Reconocimiento de gestos.ipynb: notebook de jupyter en el que se encuentra el código para la detección de gestos en lengua de signos propuesto.

La realización del código en este repositorio está basado en el sistema propuesto por @nicknochnack, cuyo repositorio se puede encontrar en este enlace: [Action Detection for Sign Language](https://github.com/nicknochnack/ActionDetectionforSignLanguage)